# 7. LLM을 통한 텍스트 생성 추론에 대한 심층 분석
# 7.1 기본 사항 이해
"""
- 추론은 훈련된 LLM을 사용하여 주어진 입력 프롬프트에서 인간과 유사한 텍스트를 생성하는 과정
- 언어 모델은 훈련에서 얻은 지식을 활용하여 한 번에 한 단어씩 응답을 구성
- 이 모델은 수십억 개의 매개변수에서 학습된 확률을 활용하여 다음 토큰을 예측하고 생성
- 이러한 순차적인 생성 과정을 통해 LLM은 일관되고 맥락적으로 관련성 있는 텍스트 생성
"""

# 7.2. attention 의 역할
"""
- attention mechanism은 맥락을 이해하고 일관된 반응을 생성하는 능력을 부여
- 다음 단어를 예측할 때, 문장의 모든 단어가 동일한 가중치를 갖는 것은 아님
- 예를 들어, "The Capital of France is..." 에서 "France"와 "Capital"은  "Paris"가 다음에 나와야한다는 것을 결정하는 데 매우 중요.
- 이처럼 관련 정보에 집중하는 능력을 attention이라고 부름
"""

# 7.3 맥락 길이와 attention 지속 시간
"""
- 맥락 길이(attention 지속 시간) : LLM이 한 번에 처리할 수 있는 토큰(단어 또는 단어의 일부)의 최대 개수를 나타냄.
                                모델은 작업 기억의 크기라고 생각하면 됨.

    - 모델의 아키텍처와 크기
    - 사용 가능한 계산 리소스
    - 입력과 원하는 출력의 복잡성

    * 컨텍스트 길이 : 모델이 응답을 생성할 때 한 번에 고려할 수 있는 토큰의 최대 수
"""

# 7.4 프롬프팅의 기술
"""
- LLM에 정보를 전달할 때, 우리는 LLM 생성이 원하는 결과를 도출하도록 입력을 구성(prompting) 
"""

# 7.5 2단계 추론 프로세스
"""
1. prefill
    1. 토큰화 : 입력 텍스트를 토큰으로 변환(모델이 이해하는 기본 구성 요소)
    2. 임베딩 변환 : 이러한 토큰을 의미를 포착하는 숫자 표현으로 변환
    3. 초기 처리 : 컨텍스트에 대한 풍부한 이해를 생성하기 위해 모델의 신경망을 통해 임베딩 실행

2. decode
    1. Attention Computation : 맥락을 이해하기 위해 이전의 모든 토큰을 되돌아봄
    2. probability Calculation : 각 다음 토큰의 가능성 결정
    3. Token Selection : 확률 기반으로 다음 토큰 선택
    4. Continuation Check : 생성을 계속할지 또는 중단할지 결정
"""

# 7.6 샘플링 전략
"""
- 토큰 선택 이해 : 확률부터 토큰 선택까지
    - 모델이 다음 토큰을 선택해야할 때, 먼저 해당 어휘에 있는 모든 단어에 대한 원시 확률(로짓)을 사용
    - 이런 확률을 실제 선택으로 어떻게 변환?
        1. 원시 로짓 : 이것을 모델의 다음 가능한 단어에 대한 초기 직감으로 생각
        2. 온도 조절 : 창의성 다이얼과 유사 - 높은 설정(>1.0)은 선택을 더 무작위적이고 창의적으로 만들고, 낮은 설정(<1.0)은 선택을 더 집중적이고 결정적으로 만듦
        3. Top-p 샘플링 : 가능한 모든 단어를 고려하는 대신 선택한 확률 임계값(예 : 상위 90%)에 합산되는 가장 가능성이 높은 단어만 살펴봄
        4. Top-k 필터링 : 가장 가능성이 높은 다음 단어 k개만 고려하는 대체 접근 방식

- 반복 관리 : 결과물을 새롭게 유지하기
            LLM의 일반적인 어려움 중 하나는 반복적인 표현을 하는 경향이 있다는 것

        1. 존재 페널티 : 이전에 등장한 모든 토큰에 적용되는 고정 페널티로, 출현 빈도와 관계없이 적용됨. 이는 모델이 동일한 단어를 재사용하는 것을 방지하는 데 도움이 됨.
        2. 빈도 페널티 : 토큰이 얼마나 자주 사용되었는지에 따라 증가하는 스케일링 페널티. 단어가 더 많이 등장할수록 다시 선택될 가능성이 줄어듦.

- 생성 길이 제어 : 경계 설정
    1. 토큰 제한 : 최소 및 최대 토큰 수 설정
    2. 정지 시퀀스 : 생성 종료를 알리는 특정 패턴 정의
    3. 시퀀스 종료 감지 : 모델이 자연스럽게 응답을 결론짓도록 함

- 빔 검색 
## 🔹 비교

### 1. **그리디 서치 (Greedy Search)**

* 매 단계에서 **가장 확률 높은 토큰 하나**만 선택.
* 예:

  ```
  입력: "나는 밥을"
  다음 후보: ["먹었다"(0.6), "좋아한다"(0.3), "안 먹는다"(0.1)]  
  → "먹었다" 선택 (끝)
  ```
* ✅ 빠름, 단순
* ❌ 초반에 잘못 고르면 문장이 어색해질 수 있음

---

### 2. **빔 서치 (Beam Search)**

* 매 단계에서 **상위 k개 후보(beam size)를 유지**
* 예 (beam size=2):

  ```
  입력: "나는 밥을"
  다음 후보: ["먹었다"(0.6), "좋아한다"(0.3), "안 먹는다"(0.1)]  
  → 상위 2개: "먹었다", "좋아한다" 유지  

  다음 단계에서:
  "먹었다 → 집에서(0.4), 맛있게(0.3)..."
  "좋아한다 → 아주(0.5), 항상(0.2)..."
  ```
* 마지막까지 문장 경로를 확장하면서, 최종적으로 **전체 확률이 가장 높은 문장**을 고름.
* ✅ 더 자연스러운 결과 가능
* ❌ 속도 느려짐, 다양성이 줄 수 있음

---

👉 즉, \*\*원래(그리디)\*\*는 매번 "1등 후보"만 따라가고,
**빔 검색**은 매번 "상위 k등까지" 후보를 동시에 따라가면서 최적의 문장을 찾음

"""

# 7.7 실제적인 과제와 최적화
# 7.7.1 주요 성과 지표
"""
- 첫 번째 토큰까지 걸리는 시간(TTFT) : 첫 번째 응답을 얼마나 빨리 받을 수 있을지. 주로 사전 입력 단계의 영향을 받음
- 출력 토큰 당 시간(TPOT) : 후속 토큰을 얼마나 빨리 생성할 수 있을지. 전체 생성 속도를 결정
- 처리량 : 동시에 얼마나 많은 요청을 처리할 수 있는지? 확장성과 비용 효율성에 영향을 미침
- VRAM 사용량 : GPU 메모리가 얼마나 필요할지. 이는 실제 애플리케이션에서 가장 큰 제약 조건이 됨.
"""

# 7.7.2 컨텍스트 길이
"""
- context가 길수록 더 많은 정보를 제공하지만 상당한 비용 발생
    - 메모리 사용량 : 컨텍스트 길이에 따라 2차적으로 증가
    - 처리 속도 : 컨텍스트가 길어질수록 선형적으로 감소
    - 리소스 할당 : VRAM 사용량을 신중하게 균형 조정
"""

# 7.8 결론
"""
- The fundamental role of attention and context
- The two-phase inference process
- Various sampling strategies for controlling generation
- Practical challenges and optimizations
"""

# 8. 편견과 한계

from transformers import pipeline

unmasker = pipeline("fill-mask", model = "bert-base-uncased")
result = unmasker("This man works as a [MASK].")
print([r["token_str"] for r in result])

result = unmasker("This woman works as a [MASK].")
print([r["token_str"] for r in result])

# ['lawyer', 'carpenter', 'doctor', 'waiter', 'mechanic']
# ['nurse', 'waitress', 'teacher', 'maid', 'prostitute']